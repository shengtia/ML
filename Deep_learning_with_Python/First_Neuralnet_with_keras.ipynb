{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries and set the ranom number generator for stochastic process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and plit it into data + label, X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset \n",
    "dataset = numpy.loadtxt(\"Accessory_files/pima-indians-diabetes.csv\", delimiter = \",\")\n",
    "\n",
    "#Split into input and output variables, rows and columns\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now define the model, build the Sequential/network topology\n",
    "1. Fully connected layer is defined using the dense class\n",
    "2. Specify the Sequential model\n",
    "3. Define the layers and number of nuerons + activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# the first hidden layer has 12 neurons and expect 8 inputs\n",
    "model.add(Dense(12, input_dim=8, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model\n",
    "1. specify the loss function to be used, the optimizer and the other optional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "1. Specify the input data and the label\n",
    "2. Number of Epoches\n",
    "3. Normally we are using batch training, so specifying the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s 451us/step - loss: 5.4888 - acc: 0.6250\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 5.2657 - acc: 0.6432\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 382us/step - loss: 5.0865 - acc: 0.6237\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 266us/step - loss: 4.5007 - acc: 0.6302\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 275us/step - loss: 3.7710 - acc: 0.6185\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 307us/step - loss: 3.4784 - acc: 0.6419\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 3.3119 - acc: 0.6432\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 1.5967 - acc: 0.6354\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.8006 - acc: 0.6641\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.7331 - acc: 0.6641\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 381us/step - loss: 0.6810 - acc: 0.6966\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.6397 - acc: 0.6888\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 324us/step - loss: 0.6743 - acc: 0.6667\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.6405 - acc: 0.6797\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.6197 - acc: 0.6771\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.6259 - acc: 0.6875\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.5991 - acc: 0.6914\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 341us/step - loss: 0.5845 - acc: 0.7083\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.5918 - acc: 0.6940\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.6150 - acc: 0.6901\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.5876 - acc: 0.7266\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 320us/step - loss: 0.6091 - acc: 0.6992\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 386us/step - loss: 0.5861 - acc: 0.6992\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 375us/step - loss: 0.6447 - acc: 0.6914\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.5758 - acc: 0.7279\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.5769 - acc: 0.7148\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 321us/step - loss: 0.5964 - acc: 0.7083\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.5787 - acc: 0.7057\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5621 - acc: 0.7266\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.5700 - acc: 0.7240\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.5609 - acc: 0.7292\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.5662 - acc: 0.7227\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.5643 - acc: 0.7318\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.5954 - acc: 0.7109\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.5881 - acc: 0.7096\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.5796 - acc: 0.7266\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.6102 - acc: 0.6927\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 350us/step - loss: 0.5529 - acc: 0.7292\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 353us/step - loss: 0.5628 - acc: 0.7240\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 337us/step - loss: 0.5701 - acc: 0.7266\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 376us/step - loss: 0.5486 - acc: 0.7331\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.5446 - acc: 0.7305\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.5541 - acc: 0.7279\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5540 - acc: 0.7266\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.5439 - acc: 0.7266\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.5757 - acc: 0.7305\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.5835 - acc: 0.6966\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5469 - acc: 0.7266\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.5641 - acc: 0.7305\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.5555 - acc: 0.7305\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.5398 - acc: 0.7318\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.5463 - acc: 0.7253\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.5388 - acc: 0.7344\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 349us/step - loss: 0.5493 - acc: 0.7240\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 353us/step - loss: 0.5391 - acc: 0.7422\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.5625 - acc: 0.7305\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 346us/step - loss: 0.5468 - acc: 0.7331\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 449us/step - loss: 0.6052 - acc: 0.7188\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.5679 - acc: 0.7344\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5576 - acc: 0.7305\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 319us/step - loss: 0.5355 - acc: 0.7448\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.5401 - acc: 0.7331\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 338us/step - loss: 0.5344 - acc: 0.7331\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 373us/step - loss: 0.5512 - acc: 0.7292\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 337us/step - loss: 0.5599 - acc: 0.7227\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.5462 - acc: 0.7279\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 320us/step - loss: 0.5442 - acc: 0.7344\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.5456 - acc: 0.7422\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5586 - acc: 0.7435\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.5597 - acc: 0.7214\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.5361 - acc: 0.7370\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5339 - acc: 0.7305\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.5306 - acc: 0.7461\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.5264 - acc: 0.7448\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.5515 - acc: 0.7266\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.5270 - acc: 0.7370\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.5503 - acc: 0.7305\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5238 - acc: 0.7383\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.5148 - acc: 0.7539\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.5360 - acc: 0.7448\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5319 - acc: 0.7396\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5216 - acc: 0.7513\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 298us/step - loss: 0.5359 - acc: 0.7383\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.5181 - acc: 0.7435\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.5245 - acc: 0.7448\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 363us/step - loss: 0.5270 - acc: 0.7396\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 364us/step - loss: 0.5165 - acc: 0.7591\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 352us/step - loss: 0.5325 - acc: 0.7487\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 406us/step - loss: 0.5767 - acc: 0.7227\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.5197 - acc: 0.7513\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.5385 - acc: 0.7370\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 416us/step - loss: 0.5153 - acc: 0.7552\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.5325 - acc: 0.7357\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.5203 - acc: 0.7513\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.5145 - acc: 0.7474\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5162 - acc: 0.7604\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.5390 - acc: 0.7396\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5331 - acc: 0.7383\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5512 - acc: 0.7292\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5208 - acc: 0.7500\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.5234 - acc: 0.7409\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5678 - acc: 0.7227\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.5232 - acc: 0.7396\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5315 - acc: 0.7422\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.5082 - acc: 0.7487\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.5178 - acc: 0.7513\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.5539 - acc: 0.7370\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.5213 - acc: 0.7461\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.5344 - acc: 0.7383\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.5182 - acc: 0.7409\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.5195 - acc: 0.7513\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.5082 - acc: 0.7513\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 261us/step - loss: 0.5190 - acc: 0.7357\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 258us/step - loss: 0.5102 - acc: 0.7552\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5303 - acc: 0.7448\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 283us/step - loss: 0.5149 - acc: 0.7448\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.5244 - acc: 0.7500\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.5160 - acc: 0.7500\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.5208 - acc: 0.7578\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.5220 - acc: 0.7409\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 278us/step - loss: 0.5102 - acc: 0.7448\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.5406 - acc: 0.7383\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.5285 - acc: 0.7396\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5256 - acc: 0.7331\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.5127 - acc: 0.7656\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 334us/step - loss: 0.5107 - acc: 0.7552\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 407us/step - loss: 0.5209 - acc: 0.7448\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.5118 - acc: 0.7578\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.5013 - acc: 0.7552\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.5436 - acc: 0.7240\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5038 - acc: 0.7539\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 284us/step - loss: 0.5212 - acc: 0.7448\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5458 - acc: 0.7318\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.5270 - acc: 0.7409\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5135 - acc: 0.7474\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.5072 - acc: 0.7474\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.5231 - acc: 0.7344\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 282us/step - loss: 0.5466 - acc: 0.7344\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.5183 - acc: 0.7578\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.5262 - acc: 0.7370\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 268us/step - loss: 0.5168 - acc: 0.7461\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 272us/step - loss: 0.5163 - acc: 0.7526\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 269us/step - loss: 0.5191 - acc: 0.7435\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 280us/step - loss: 0.5080 - acc: 0.7513\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5393 - acc: 0.7396\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 357us/step - loss: 0.5350 - acc: 0.7448\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.5094 - acc: 0.7513\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 390us/step - loss: 0.5104 - acc: 0.7487\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 398us/step - loss: 0.5097 - acc: 0.7422\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 348us/step - loss: 0.5038 - acc: 0.7513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119187400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X,Y, epochs= 150, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "1. Only training accuracy for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 43us/step\n",
      "\n",
      "acc: 76.04%\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
